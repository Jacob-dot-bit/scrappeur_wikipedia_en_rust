# Scrappeur Wikipedia en Rust

Un scrappeur web performant et interactif dÃ©veloppÃ© en Rust pour extraire automatiquement des informations depuis les pages Wikipedia.

## ğŸ“‹ Table des matiÃ¨res

- [Description](#description)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Structure du projet](#structure-du-projet)
- [DÃ©pendances](#dÃ©pendances)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [RÃ©solution des problÃ¨mes](#rÃ©solution-des-problÃ¨mes)
- [Exemples](#exemples)

## ğŸ¯ Description

Ce projet permet de scraper des pages Wikipedia en franÃ§ais et d'extraire :
- Le titre de la page
- Le rÃ©sumÃ© (premier paragraphe)
- Les sections et sous-sections
- Les liens internes vers d'autres pages
- Les images prÃ©sentes sur la page

Les donnÃ©es extraites sont ensuite sauvegardÃ©es au format JSON avec le nom du sujet recherchÃ©.

## âœ¨ FonctionnalitÃ©s

- âœ… **Mode interactif** : interface utilisateur en ligne de commande
- âœ… **Arguments CLI** : utilisation via arguments (--sujet, --url, --interactif)
- âœ… **Recherche flexible** : par sujet, URL complÃ¨te ou mot-clÃ©
- âœ… Scraping asynchrone pour de meilleures performances
- âœ… Extraction structurÃ©e des donnÃ©es
- âœ… Export automatique en JSON avec nom personnalisÃ©
- âœ… Gestion des erreurs robuste
- âœ… User-Agent personnalisÃ© pour Ã©viter les blocages
- âœ… Filtrage intelligent des liens et images

## ğŸ“ Structure du projet

```
Scrappeur wikipedia/
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.rs              # Fichier principal contenant toute la logique
â”‚
â”œâ”€â”€ target/                  # Dossier gÃ©nÃ©rÃ© par Cargo (compilations)
â”‚   â”œâ”€â”€ debug/              # Build en mode debug
â”‚   â””â”€â”€ release/            # Build en mode release (optimisÃ©)
â”‚
â”œâ”€â”€ Cargo.toml              # Manifeste du projet et dÃ©pendances
â”œâ”€â”€ Cargo.lock              # Verrouillage des versions des dÃ©pendances
â”œâ”€â”€ .gitignore              # Fichiers Ã  ignorer par Git
â”œâ”€â”€ README.md               # Ce fichier
â””â”€â”€ *.json                  # Fichiers JSON gÃ©nÃ©rÃ©s aprÃ¨s exÃ©cution
```

### Description des fichiers et dossiers

#### `src/main.rs`
**RÃ´le** : Fichier source principal du projet
- **Structure `WikipediaPage`** : Stocke les donnÃ©es extraites
- **Structure `Args`** : GÃ¨re les arguments CLI avec clap
- **Fonction `main()`** : Point d'entrÃ©e asynchrone, gÃ¨re la logique de choix (interactif/CLI)
- **Fonction `get_user_input()`** : Interface interactive pour choisir le mode de recherche
- **Fonction `sanitize_filename()`** : Nettoie le nom du fichier JSON gÃ©nÃ©rÃ©
- **Fonction `scrape_wikipedia()`** : Logique de scraping et parsing HTML avec sÃ©lecteurs CSS

#### `Cargo.toml`
**RÃ´le** : Fichier de configuration du projet
- DÃ©finit le nom, version et Ã©dition Rust du projet
- Liste toutes les dÃ©pendances externes nÃ©cessaires
- Configure les features spÃ©cifiques des dÃ©pendances

#### `Cargo.lock`
**RÃ´le** : Verrouillage des versions
- GÃ©nÃ©rÃ© automatiquement par Cargo
- Garantit la reproductibilitÃ© des builds
- **Ne pas modifier manuellement**

#### `target/`
**RÃ´le** : Dossier de compilation
- GÃ©nÃ©rÃ© automatiquement lors du `cargo build` ou `cargo run`
- Contient les fichiers binaires compilÃ©s et les dÃ©pendances
- Peut Ãªtre supprimÃ© sans risque (`cargo clean`)

#### `.gitignore`
**RÃ´le** : Exclusions Git
- EmpÃªche le versionnement de `target/`, fichiers JSON et `Cargo.lock`
- RÃ©duit la taille du repository

#### `*.json` (ex: `Rust_(langage).json`)
**RÃ´le** : Sorties du scraping
- GÃ©nÃ©rÃ©s aprÃ¨s l'exÃ©cution du programme
- Nom basÃ© sur le titre de la page Wikipedia
- Contiennent les donnÃ©es extraites au format JSON structurÃ©

## ğŸ“¦ DÃ©pendances

Le projet utilise les crates suivantes :

### 1. **reqwest** (v0.11)
- **RÃ´le** : Client HTTP asynchrone
- **Usage** : RÃ©cupÃ©ration du contenu HTML des pages Wikipedia
- **Feature** : `json` pour la sÃ©rialisation JSON

### 2. **tokio** (v1.0)
- **RÃ´le** : Runtime asynchrone
- **Usage** : Permet l'exÃ©cution asynchrone du code
- **Feature** : `full` pour toutes les fonctionnalitÃ©s

### 3. **scraper** (v0.18)
- **RÃ´le** : Parser et sÃ©lecteur HTML
- **Usage** : Extraction des Ã©lÃ©ments HTML via sÃ©lecteurs CSS
- **BasÃ© sur** : html5ever et selectors

### 4. **serde** (v1.0)
- **RÃ´le** : Framework de sÃ©rialisation/dÃ©sÃ©rialisation
- **Usage** : Conversion des structures Rust en JSON
- **Feature** : `derive` pour les macros

### 5. **serde_json** (v1.0)
- **RÃ´le** : Support JSON pour serde
- **Usage** : Ã‰criture du fichier JSON de sortie

### 6. **clap** (v4.5) â­ NOUVEAU
- **RÃ´le** : Parser d'arguments en ligne de commande
- **Usage** : Gestion des options --sujet, --url, --interactif
- **Feature** : `derive` pour les macros

### Graphe de dÃ©pendances

```
main.rs
  â”œâ”€â”€ reqwest (HTTP client)
  â”‚     â””â”€â”€ tokio (runtime async)
  â”œâ”€â”€ scraper (HTML parsing)
  â”‚     â”œâ”€â”€ html5ever
  â”‚     â””â”€â”€ selectors
  â”œâ”€â”€ serde (serialization)
  â”œâ”€â”€ serde_json (JSON support)
  â”‚     â””â”€â”€ serde
  â””â”€â”€ clap (CLI arguments) â­ NOUVEAU
```

## ğŸš€ Installation

### PrÃ©requis

- **Rust** : Version 1.70 ou supÃ©rieure
- **Cargo** : Gestionnaire de paquets Rust (inclus avec Rust)

### Installer Rust

Si vous n'avez pas Rust installÃ© :

**Windows** :
```powershell
# TÃ©lÃ©chargez et exÃ©cutez rustup-init.exe depuis https://rustup.rs/
# Ou utilisez winget :
winget install Rustlang.Rustup
```

**Linux/macOS** :
```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

### Cloner ou crÃ©er le projet

```bash
# Si vous clonez depuis Git
git clone <votre-repo>
cd "Scrappeur wikipedia"

# Ou crÃ©ez un nouveau projet
cargo new "Scrappeur wikipedia"
cd "Scrappeur wikipedia"
```

### Installer les dÃ©pendances

```bash
# Les dÃ©pendances seront automatiquement tÃ©lÃ©chargÃ©es lors du premier build
cargo build
```

## ğŸ’» Utilisation

### ğŸ® Mode 1 : Interactif (RecommandÃ©)

Le mode par dÃ©faut qui vous guide pas Ã  pas :

```bash
cargo run
```

Vous verrez un menu :
```
=== Scraper Wikipedia ===

Choisissez une option :
1. Entrer un sujet (ex: Rust_(langage))
2. Entrer une URL complÃ¨te
3. Rechercher par mot-clÃ©

Votre choix (1-3) :
```

**Option 1** : Format exact de Wikipedia (avec underscores)
- Exemple : `Python_(langage)`, `Intelligence_artificielle`

**Option 2** : Coller l'URL complÃ¨te
- Exemple : `https://fr.wikipedia.org/wiki/JavaScript`

**Option 3** : Recherche simple (espaces automatiquement convertis)
- Exemple : `langage de programmation` â†’ `langage_de_programmation`

### ğŸš€ Mode 2 : Ligne de commande

#### Recherche par sujet
```bash
cargo run -- --sujet "Rust_(langage)"
cargo run -- -s "Python_(langage)"
```

#### Recherche par URL complÃ¨te
```bash
cargo run -- --url "https://fr.wikipedia.org/wiki/JavaScript"
cargo run -- -u "https://fr.wikipedia.org/wiki/TypeScript"
```

#### Forcer le mode interactif
```bash
cargo run -- --interactif
cargo run -- -i
```

### ğŸ“– Aide

Afficher toutes les options disponibles :
```bash
cargo run -- --help
```

### ğŸ“¤ Sortie du programme

Le programme :
1. **Affiche dans le terminal** :
   - Le titre de la page
   - Le rÃ©sumÃ© complet
   - Le nombre de sections, liens et images
   - Les 5 premiÃ¨res sections

2. **GÃ©nÃ¨re un fichier JSON** :
   - Nom : `{Titre_de_la_page}.json`
   - Contenu : Toutes les donnÃ©es structurÃ©es

### Exemple de sortie console

```
Scraping de la page Wikipedia : https://fr.wikipedia.org/wiki/Rust_(langage)

=== RÃ©sultats du Scraping ===

Titre: Rust (langage)

RÃ©sumÃ©:
Rust est un langage de programmation compilÃ© multi-paradigme...

Nombre de sections: 15
Nombre de liens: 50
Nombre d'images: 20

PremiÃ¨res sections:
  1. Histoire
  2. CaractÃ©ristiques
  3. Syntaxe
  4. Gestion de la mÃ©moire
  5. Ã‰cosystÃ¨me

DonnÃ©es sauvegardÃ©es dans 'Rust_(langage).json'
```

### Exemple de fichier JSON gÃ©nÃ©rÃ©

```json
{
  "title": "Rust (langage)",
  "summary": "Rust est un langage de programmation compilÃ© multi-paradigme...",
  "sections": [
    "Histoire",
    "CaractÃ©ristiques",
    "Syntaxe",
    "Gestion de la mÃ©moire",
    "Ã‰cosystÃ¨me"
  ],
  "links": [
    "https://fr.wikipedia.org/wiki/Langage_de_programmation",
    "https://fr.wikipedia.org/wiki/Mozilla",
    "https://fr.wikipedia.org/wiki/C%2B%2B"
  ],
  "images": [
    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Rust_programming_language_black_logo.svg/1200px-Rust_programming_language_black_logo.svg.png"
  ]
}
```

## ğŸ”§ RÃ©solution des problÃ¨mes

### Erreur "AccÃ¨s refusÃ©" (Windows)

**ProblÃ¨me** : `error: AccÃ¨s refusÃ©. (os error 5)`

**Solutions** :
1. **Fermez tous les IDE/Ã©diteurs** ouverts sur le projet
2. **Nettoyez le projet** : `cargo clean`
3. **ExÃ©cutez PowerShell en tant qu'administrateur`
4. **âš ï¸ IMPORTANT : DÃ©placez le projet hors de OneDrive** 
   - De : `C:\Users\Admin\OneDrive\Bureau\ESGI\BAC +4\RUST\Scrappeur wikipedia`
   - Vers : `C:\Users\Admin\Documents\RUST\Scrappeur wikipedia`
   - OneDrive interfÃ¨re avec la compilation Rust
5. **Ajoutez une exclusion antivirus** pour le dossier `target/`

### Erreur de connexion rÃ©seau

**ProblÃ¨me** : Le scraping Ã©choue avec une erreur rÃ©seau

**Solutions** :
- VÃ©rifiez votre connexion Internet
- VÃ©rifiez que Wikipedia n'est pas bloquÃ© par votre pare-feu
- Le serveur peut avoir temporairement bloquÃ© les requÃªtes : attendez quelques minutes
- Essayez avec un autre sujet

### Le JSON est vide ou incomplet

**ProblÃ¨me** : Les sÃ©lecteurs ne trouvent pas les Ã©lÃ©ments

**Solutions** :
- Wikipedia peut avoir changÃ© sa structure HTML
- VÃ©rifiez que l'URL est correcte et la page existe
- Certaines pages Wikipedia ont une structure diffÃ©rente
- Testez avec des pages populaires : `Rust_(langage)`, `Python_(langage)`, `JavaScript`

### Page Wikipedia introuvable

**ProblÃ¨me** : Erreur 404 ou page vide

**Solutions** :
- VÃ©rifiez l'orthographe du sujet
- Utilisez le format exact de Wikipedia (avec underscores et parenthÃ¨ses)
- Copiez l'URL directement depuis votre navigateur (option 2 du mode interactif)
- Essayez la recherche par mot-clÃ© (option 3)

### CaractÃ¨res spÃ©ciaux dans le nom de fichier

**ProblÃ¨me** : Le fichier JSON n'est pas crÃ©Ã©

**Solutions** :
- La fonction `sanitize_filename()` remplace automatiquement les caractÃ¨res interdits
- Si le problÃ¨me persiste, le titre sera tronquÃ© Ã  50 caractÃ¨res maximum

## ğŸ“š Exemples d'utilisation

### Exemple 1 : Scraper plusieurs sujets en boucle

CrÃ©ez un script bash/PowerShell :

**PowerShell** :
```powershell
$sujets = @(
    "Rust_(langage)",
    "Python_(langage)",
    "JavaScript",
    "Intelligence_artificielle"
)

foreach ($sujet in $sujets) {
    Write-Host "Scraping de $sujet..." -ForegroundColor Green
    cargo run -- --sujet $sujet
    Start-Sleep -Seconds 2  # Pause de 2 secondes entre chaque requÃªte
}
```

**Bash** :
```bash
#!/bin/bash
sujets=("Rust_(langage)" "Python_(langage)" "JavaScript" "Intelligence_artificielle")

for sujet in "${sujets[@]}"; do
    echo "Scraping de $sujet..."
    cargo run -- --sujet "$sujet"
    sleep 2  # Pause de 2 secondes
done
```

### Exemple 2 : Modifier le code pour extraire plus d'informations

Pour limiter ou augmenter le nombre de liens/images, modifiez dans `src/main.rs` :

```rust
// Actuellement : 50 liens maximum
.take(50)  // Changez en .take(100) pour plus de liens

// Actuellement : 20 images maximum
.take(20)  // Changez en .take(50) pour plus d'images
```

### Exemple 3 : Filtrer les sections spÃ©cifiques

AprÃ¨s le scraping, ajoutez dans `main()` :

```rust
// Extraire seulement les sections contenant certains mots-clÃ©s
let sections_filtrees: Vec<String> = page_data.sections
    .iter()
    .filter(|s| s.contains("Histoire") || s.contains("Syntaxe"))
    .cloned()
    .collect();

println!("Sections filtrÃ©es: {:?}", sections_filtrees);
```

### Exemple 4 : Scraper en mode release (plus rapide)

```bash
cargo build --release
./target/release/wikipedia_scraper --sujet "Rust_(langage)"
```

## ğŸ“ Cas d'usage pÃ©dagogiques

Ce projet est idÃ©al pour apprendre :
- **Web scraping** avec Rust
- **Programmation asynchrone** avec tokio
- **Parsing HTML** avec scraper
- **CLI arguments** avec clap
- **SÃ©rialisation JSON** avec serde
- **Gestion d'erreurs** en Rust
- **RequÃªtes HTTP** avec reqwest

## ğŸ“ Licence

Ce projet est Ã  usage Ã©ducatif. Respectez les conditions d'utilisation de Wikipedia lors du scraping :
- Ne pas surcharger les serveurs (ajoutez des pauses entre les requÃªtes)
- Respecter le fichier robots.txt
- Utiliser pour des fins d'apprentissage

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs via les issues
- Proposer des amÃ©liorations
- Ajouter de nouvelles fonctionnalitÃ©s (export CSV, scraping multilingue, etc.)
- AmÃ©liorer la documentation

## ğŸ“ Contact

Projet ESGI - BAC +4 RUST

---

**Note importante** : Ce scrappeur utilise un User-Agent appropriÃ© et respecte les bonnes pratiques du web scraping. Utilisez-le de maniÃ¨re responsable et Ã©thique.
